import os
import json
import re
from dotenv import load_dotenv, find_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_community.vectorstores import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from pydantic import BaseModel, Field

from app.prompts import few_shot_examples, system_prompt_content

# --- è¼‰å…¥ç’°å¢ƒè®Šæ•¸ ---
env_file = find_dotenv()
if env_file: load_dotenv(env_file)

# --- 1. æ–°ç‰ˆè³‡æ–™çµæ§‹å®šç¾© (æ”¯æ´é¡Œçµ„) ---

class SubQuestion(BaseModel):
    id: str = Field(description="å­é¡Œç·¨è™Ÿï¼Œä¾‹å¦‚ (1), (2)")
    question_text: str = Field(description="é¡Œç›®æ•˜è¿°")
    options: list[str] = Field(description="é¸é … (A, B, C, D)")
    correct_answer: str = Field(description="æ­£ç¢ºç­”æ¡ˆ")
    explanation: str = Field(description="è§£æ")

class QuestionBlock(BaseModel):
    type: str = Field(description="é¡å‹ï¼šå–®é¡Œ / é¡Œçµ„ / æ··åˆé¡Œçµ„")
    difficulty: str = Field(description="é›£åº¦")
    article_content: str = Field(description="é–±è®€æ¸¬é©—çš„æ–‡ç« å…§å®¹ (è‹¥ç‚ºå–®é¡Œå‰‡ç•™ç©ºï¼Œè‹¥ç‚ºé¡Œçµ„è«‹å¡«å…¥ç”²ã€ä¹™ç­‰å¼•æ–‡)")
    questions: list[SubQuestion] = Field(description="æ­¤å€å¡ŠåŒ…å«çš„é¡Œç›®åˆ—è¡¨")

class ExamPaper(BaseModel):
    main_scope_text: str = Field(description="æ¸¬é©—ç¯„åœèªªæ˜")
    question_blocks: list[QuestionBlock] = Field(description="è©¦é¡Œå€å¡Šåˆ—è¡¨")

# --- 2. æ¸…æ´—å‡½å¼ ---
def clean_and_parse_json(ai_response_text):
    try:
        text = ai_response_text.strip()
        if "```json" in text: text = text.split("```json")[1].split("```")[0]
        elif "```" in text: text = text.split("```")[1].split("```")[0]
        
        start_idx = text.find("{")
        end_idx = text.rfind("}") + 1
        if start_idx != -1 and end_idx != -1:
            return json.loads(text[start_idx:end_idx])
        else:
            raise ValueError("ç„¡æ•ˆçš„ JSON çµæ§‹")
    except Exception as e:
        print(f"âŒ JSON è§£æå¤±æ•—: {e}")
        return {"main_scope_text": "è§£æéŒ¯èª¤", "question_blocks": []}

# --- 3. æª¢ç´¢å‡½å¼ ---
def retrieve_docs(selected_texts):
    db_path = "./data/chroma_db"
    if not os.path.exists(db_path): return "ï¼ˆè­¦å‘Šï¼šå°šæœªå»ºç«‹ RAG è³‡æ–™åº«ï¼‰"

    embedding_model = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
    vectorstore = Chroma(persist_directory=db_path, embedding_function=embedding_model)
    
    retrieved_content = ""
    for item in selected_texts:
        title_keyword = item.split("-")[1].strip() if "-" in item else item
        print(f"ğŸ” [RAG] æœå°‹ï¼š{title_keyword}")
        
        try:
            results = vectorstore.similarity_search(query=title_keyword, k=2, filter={"title": title_keyword})
            if results:
                for doc in results:
                    retrieved_content += f"\n\n--- é¸æ–‡ï¼š{doc.metadata.get('title', 'æœªçŸ¥')} ---\n{doc.page_content}"
            else:
                retrieved_content += f"\n\nï¼ˆæœªæ‰¾åˆ° {title_keyword} çš„åŸæ–‡ï¼‰"
        except Exception as e:
            retrieved_content += f"\n\nï¼ˆæœå°‹éŒ¯èª¤ï¼š{e}ï¼‰"

    return retrieved_content

# --- 4. å»ºç«‹ Chain ---
def get_exam_generator_chain():
    api_key = os.getenv("OPENROUTER_API_KEY")
    base_url = os.getenv("OPENROUTER_BASE_URL")
    model_name = os.getenv("OPENROUTER_MODEL")

    if not api_key:
        api_key = os.getenv("OPENAI_API_KEY")
        if not os.getenv("OPENROUTER_API_KEY"): base_url = None 

    if not api_key: raise ValueError("âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° API Key")

    llm = ChatOpenAI(
        model=model_name if model_name else "gpt-4o",
        api_key=api_key,
        base_url=base_url,
        temperature=0.7
    )
    
    example_prompt = ChatPromptTemplate.from_messages(
        [("human", "{instruction}\n\nåƒè€ƒæ–‡æœ¬ï¼š\n{context}"), ("ai", "{output_json}")]
    )
    few_shot_prompt = FewShotChatMessagePromptTemplate(
        example_prompt=example_prompt,
        examples=few_shot_examples,
    )

    final_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_prompt_content),
            few_shot_prompt,
            ("human", "{user_request}\n\n{format_instructions}"),
        ]
    )

    chain = final_prompt | llm | StrOutputParser() | clean_and_parse_json
    return chain