import os
import sys
from dotenv import load_dotenv, find_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langchain_community.vectorstores import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from pydantic import BaseModel, Field

from app.prompts import few_shot_examples, system_prompt_content

# --- å¼·åˆ¶å°‹æ‰¾ä¸¦è¼‰å…¥ .env ---
# é€™æ¨£å¯«å¯ä»¥é¿å… streamlit æœ‰æ™‚å€™æ‰¾ä¸åˆ°æª”æ¡ˆçš„å•é¡Œ
env_file = find_dotenv()
if env_file:
    load_dotenv(env_file)
    print(f"âœ… æˆåŠŸè¼‰å…¥ç’°å¢ƒè®Šæ•¸æª”æ¡ˆ: {env_file}")
else:
    print("âŒ è­¦å‘Šï¼šæ‰¾ä¸åˆ° .env æª”æ¡ˆï¼è«‹ç¢ºèªå®ƒåœ¨å°ˆæ¡ˆæ ¹ç›®éŒ„ã€‚")

# --- é™¤éŒ¯ï¼šæª¢æŸ¥æ˜¯å¦æœ‰è®€åˆ°é‡‘é‘° ---
api_key_check = os.getenv("OPENROUTER_API_KEY")
if not api_key_check:
    # å˜—è©¦è®€å– OpenAI
    api_key_check = os.getenv("OPENAI_API_KEY")
    if not api_key_check:
        print("âŒ åš´é‡éŒ¯èª¤ï¼šç¨‹å¼ç¢¼è®€å–ä¸åˆ°ä»»ä½• API Keyï¼")
    else:
        print(f"â„¹ï¸ ä½¿ç”¨ OpenAI API Key (å‰å¹¾ç¢¼: {api_key_check[:5]}...)")
else:
    print(f"â„¹ï¸ ä½¿ç”¨ OpenRouter API Key (å‰å¹¾ç¢¼: {api_key_check[:5]}...)")


# 1. è³‡æ–™çµæ§‹å®šç¾©
class Question(BaseModel):
    id: str = Field(description="é¡Œè™Ÿ")
    difficulty: str = Field(description="é›£åº¦")
    type: str = Field(description="é¡Œå‹")
    question_text: str = Field(description="é¡Œç›®æ•˜è¿°")
    options: list[str] = Field(description="é¸é …")
    correct_answer: str = Field(description="ç­”æ¡ˆ")
    explanation: str = Field(description="è§£æ")

class ExamPaper(BaseModel):
    main_text: str = Field(description="é–±è®€æ¸¬é©—çš„æ–‡æœ¬å…§å®¹")
    questions: list[Question] = Field(description="é¡Œç›®åˆ—è¡¨")

# 2. æª¢ç´¢å‡½å¼ (ä½¿ç”¨æœ¬åœ°æ¨¡å‹)
def retrieve_docs(selected_texts):
    db_path = "./data/chroma_db"
    
    if not os.path.exists(db_path):
        return "ï¼ˆè­¦å‘Šï¼šå°šæœªå»ºç«‹ RAG è³‡æ–™åº«ï¼Œè«‹å…ˆåŸ·è¡Œ rag_builder.pyï¼‰"

    # ä½¿ç”¨ HuggingFace æœ¬åœ°æ¨¡å‹ (å…è²»)
    embedding_model = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

    vectorstore = Chroma(
        persist_directory=db_path, 
        embedding_function=embedding_model
    )
    
    retrieved_content = ""
    
    for item in selected_texts:
        if "-" in item:
            title_keyword = item.split("-")[1].strip()
        else:
            title_keyword = item

        print(f"ğŸ” [RAG] æ­£åœ¨è³‡æ–™åº«æœå°‹ï¼š{title_keyword}")
        
        try:
            results = vectorstore.similarity_search(
                query=title_keyword,
                k=2,
                filter={"title": title_keyword}
            )
            
            if results:
                for doc in results:
                    retrieved_content += f"\n\n--- é¸æ–‡ï¼š{doc.metadata.get('title', 'æœªçŸ¥')} ---\n{doc.page_content}"
            else:
                retrieved_content += f"\n\nï¼ˆæœªæ‰¾åˆ° {title_keyword} çš„åŸæ–‡ï¼‰"
        except Exception as e:
            print(f"âš ï¸ æœå°‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            retrieved_content += f"\n\nï¼ˆæœå°‹ {title_keyword} æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼‰"

    return retrieved_content

# 3. å»ºç«‹ Chain çš„å‡½å¼
def get_exam_generator_chain():
    # è®€å–ç’°å¢ƒè®Šæ•¸
    api_key = os.getenv("OPENROUTER_API_KEY")
    base_url = os.getenv("OPENROUTER_BASE_URL")
    model_name = os.getenv("OPENROUTER_MODEL")

    # å¦‚æœæ²’è¨­å®š OpenRouterï¼Œå˜—è©¦è®€å– OpenAI
    if not api_key:
        api_key = os.getenv("OPENAI_API_KEY")
        # å¦‚æœåˆ‡æ›å› OpenAIï¼Œè¦æ¸…ç©º base_url é¿å…éŒ¯èª¤
        if not os.getenv("OPENROUTER_API_KEY"): 
            base_url = None 

    if not api_key:
        raise ValueError("âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° API Keyï¼Œè«‹æª¢æŸ¥ .env æª”æ¡ˆè¨­å®šï¼")

    # åˆå§‹åŒ–æ¨¡å‹
    llm = ChatOpenAI(
        model=model_name if model_name else "gpt-4o",
        api_key=api_key,
        base_url=base_url,
        temperature=0.7
    )
    
    parser = JsonOutputParser(pydantic_object=ExamPaper)

    example_prompt = ChatPromptTemplate.from_messages(
        [("human", "{instruction}\n\nåƒè€ƒæ–‡æœ¬ï¼š\n{context}"), ("ai", "{output_json}")]
    )
    few_shot_prompt = FewShotChatMessagePromptTemplate(
        example_prompt=example_prompt,
        examples=few_shot_examples,
    )

    final_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_prompt_content),
            few_shot_prompt,
            ("human", "{user_request}\n\n{format_instructions}"),
        ]
    )

    chain = final_prompt | llm | parser
    return chain