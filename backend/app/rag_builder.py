import os
import shutil
from dotenv import load_dotenv
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
# æ”¹ç”¨å…è²»çš„ HuggingFace æœ¬åœ°æ¨¡å‹
from langchain_huggingface import HuggingFaceEmbeddings

load_dotenv()

def build_database():
    base_path = "./data/knowledge_base"
    db_path = "./data/chroma_db"

    documents = []
    
    if not os.path.exists(base_path):
        print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°è·¯å¾‘ {base_path}")
        return

    print("ğŸš€ é–‹å§‹æƒæçŸ¥è­˜åº«...")

    # 1. è®€å–æª”æ¡ˆ
    for root, dirs, files in os.walk(base_path):
        for file in files:
            if file.endswith(".md") or file.endswith(".txt"):
                file_path = os.path.join(root, file)
                folder_name = os.path.basename(root)
                file_name = os.path.splitext(file)[0]

                try:
                    loader = TextLoader(file_path, encoding="utf-8")
                    docs = loader.load()
                    
                    for doc in docs:
                        doc.metadata["era"] = folder_name
                        doc.metadata["title"] = file_name
                        doc.metadata["source"] = file_name
                    
                    documents.extend(docs)
                    print(f"   âœ… å·²è®€å–ï¼š[{folder_name}] {file_name}")
                    
                except Exception as e:
                    print(f"   âš ï¸ è®€å–å¤±æ•— {file_name}: {e}")

    if not documents:
        print("âŒ æœªç™¼ç¾ä»»ä½•æ–‡ä»¶ã€‚")
        return

    # 2. åˆ‡å‰²æ–‡å­—
    print(f"ğŸ“¦ æ­£åœ¨åˆ‡å‰² {len(documents)} ä»½æ–‡ä»¶...")
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,  # æœ¬åœ°æ¨¡å‹å»ºè­°åˆ‡å°ä¸€é»ï¼Œæ•ˆæœè¼ƒå¥½
        chunk_overlap=100,
        separators=["\n\n", "\n", "ã€‚", "ï¼"]
    )
    splits = text_splitter.split_documents(documents)

    # 3. æ¸…é™¤èˆŠè³‡æ–™åº« (éå¸¸é‡è¦ï¼å› ç‚ºæ¨¡å‹æ›äº†ï¼Œå‘é‡ç¶­åº¦ä¸åŒï¼Œå¿…é ˆé‡è“‹)
    if os.path.exists(db_path):
        try:
            shutil.rmtree(db_path)
            print("ğŸ§¹ å·²æ¸…é™¤èˆŠçš„è³‡æ–™åº« (å› ç‚ºæ›´æ›æ¨¡å‹)")
        except Exception as e:
            print(f"âš ï¸ ç„¡æ³•åˆªé™¤èˆŠè³‡æ–™åº«ï¼Œè«‹æ‰‹å‹•åˆªé™¤ {db_path} è³‡æ–™å¤¾å¾Œå†è©¦: {e}")
            return

    # 4. å»ºç«‹å‘é‡è³‡æ–™åº« (ä½¿ç”¨æœ¬åœ° CPU æ¨¡å‹)
    print(f"ğŸ’¾ æ­£åœ¨ä½¿ç”¨æœ¬åœ°æ¨¡å‹ (HuggingFace) å»ºç«‹ç´¢å¼•... (ç¬¬ä¸€æ¬¡åŸ·è¡Œæœƒä¸‹è¼‰æ¨¡å‹ï¼Œè«‹ç¨å€™)")
    
    # ä½¿ç”¨å…è²»ã€è¼•é‡ç´šçš„ all-MiniLM-L6-v2 æ¨¡å‹
    embedding_model = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

    vectorstore = Chroma.from_documents(
        documents=splits,
        embedding=embedding_model,
        persist_directory=db_path
    )
    print(f"ğŸ‰ æˆåŠŸï¼RAG çŸ¥è­˜åº«å·²å»ºç«‹æ–¼ {db_path}")

if __name__ == "__main__":
    build_database()